{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJanbandhu/Prompt_Engineering/blob/main/Zoom_Quiz_or_Poll.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import base64\n",
        "\n",
        "# Replace these with your actual client ID, client secret, and account ID\n",
        "client_id = 'client_id'\n",
        "client_secret = 'client_secret'\n",
        "account_id = 'account_id'\n",
        "\n",
        "# Encode the client ID and client secret in Base64\n",
        "credentials = f'{client_id}:{client_secret}'\n",
        "encoded_credentials = base64.b64encode(credentials.encode()).decode()\n",
        "\n",
        "# Zoom API token endpoint\n",
        "token_url = 'https://zoom.us/oauth/token'\n",
        "\n",
        "# Payload and headers for the request\n",
        "payload = {\n",
        "    'grant_type': 'account_credentials',\n",
        "    'account_id': account_id\n",
        "}\n",
        "\n",
        "headers = {\n",
        "    'Host': 'zoom.us',\n",
        "    'Authorization': f'Basic {encoded_credentials}'\n",
        "}\n",
        "\n",
        "# Make the POST request to get the access token\n",
        "response = requests.post(token_url, headers=headers, data=payload)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    access_token = response.json()['access_token']\n",
        "    print(f\"Access Token: {access_token}\")\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}\")\n",
        "    print(response.json())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAV3Vl8c8o2U",
        "outputId": "a418c02e-37f7-4707-c8d1-f66134e8c488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access Token: eyJzdiI6IjAwMDAwMSIsImFsZyI6IkhTNTEyIiwidiI6IjIuMCIsImtpZCI6ImJmZDQ1OTg0LTFlYTktNGQwZC1hYzQxLTY5NzgxNDVkNGVhNSJ9.eyJhdWQiOiJodHRwczovL29hdXRoLnpvb20udXMiLCJ1aWQiOiJwLWZnVl80UFREZS1VU2syVUQ2ZWN3IiwidmVyIjo5LCJhdWlkIjoiMWY4MGNmNzBlYjkyYTYwNDllYzEyYjIzNzQ2N2NjMGEiLCJuYmYiOjE3MTk1MTMwNDYsImNvZGUiOiJPLTFKLUxvclFOcVNJWEdOLU8xbTZnWnl4d3lDcjcyYkIiLCJpc3MiOiJ6bTpjaWQ6M1U3R21zdDZRM1NRNnV2Rl9hZkRHQSIsImdubyI6MCwiZXhwIjoxNzE5NTE2NjQ2LCJ0eXBlIjozLCJpYXQiOjE3MTk1MTMwNDYsImFpZCI6InFua3RvT3JKVEx5WTlTVUJLdE9lbEEifQ.R3rWrGcOg9Urkm67BgfRaMdwCSwddFY9lzbMuBVweP57q0lTnfDzVWPLIrQiI1XH4emxnHdIBIMRbjbGowZx6A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Replace these with your access token and meeting ID\n",
        "#access_token = 'YOUR_ACCESS_TOKEN'\n",
        "meeting_id = '82179939741'\n",
        "\n",
        "# Zoom API endpoint to create a poll\n",
        "url = f'https://api.zoom.us/v2/meetings/{meeting_id}/polls'\n",
        "\n",
        "# Poll details\n",
        "poll_data = {\n",
        "    \"title\": \"Sample Poll\",\n",
        "    \"questions\": [\n",
        "        {\n",
        "            \"name\": \"What is your favorite color?\",\n",
        "            \"type\": \"single\",\n",
        "            \"answers\": [\n",
        "                \"Red\",\n",
        "                \"Blue\",\n",
        "                \"Green\",\n",
        "                \"Yellow\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"What is your favorite animal?\",\n",
        "            \"type\": \"multiple\",\n",
        "            \"answers\": [\n",
        "                \"Dog\",\n",
        "                \"Cat\",\n",
        "                \"Bird\",\n",
        "                \"Fish\"\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "headers = {\n",
        "    'Authorization': f'Bearer {access_token}',\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "# Make the API request to create the poll\n",
        "response = requests.post(url, headers=headers, json=poll_data)\n",
        "\n",
        "if response.status_code == 201:\n",
        "    print(\"Poll created successfully!\")\n",
        "    print(response.json())\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}\")\n",
        "    print(response.json())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE1frhzK-Ife",
        "outputId": "b497a4c5-9e66-4a46-d2a0-83d773468240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 400\n",
            "{'code': 4400, 'message': \"Meeting polls disabled. To enable this feature, enable the 'Meeting Polls/Quizzes' setting in the Zoom web portal's 'Settings' interface.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import base64\n",
        "\n",
        "\n",
        "\n",
        "# Zoom API endpoint to create a poll\n",
        "url = f'https://api.zoom.us/v2/meetings/{meeting_id}/polls'\n",
        "\n",
        "# Quiz poll details\n",
        "poll_data = {\n",
        "    \"title\": \"Technical Quiz\",\n",
        "    \"questions\": [\n",
        "        {\n",
        "            \"name\": \"Which of the following best describes the computational effort required for the pretraining stage in the GPT training pipeline?\",\n",
        "            \"type\": \"single\",\n",
        "            \"answers\": [\n",
        "                \"50% of the total training compute time\",\n",
        "                \"75% of the total training compute time\",\n",
        "                \"99% of the total training compute time\",\n",
        "                \"25% of the total training compute time\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"What type of datasets form the training set for GPT pretraining according to the talk?\",\n",
        "            \"type\": \"single\",\n",
        "            \"answers\": [\n",
        "                \"Exclusively curated high-quality datasets\",\n",
        "                \"A mixture of web scraped data and high-quality datasets\",\n",
        "                \"Only web scraped data from CommonCrawl\",\n",
        "                \"Proprietary datasets only from GitHub and Wikipedia\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"In the tokenization process of GPT training, which of the following algorithms is mentioned as a typical method used?\",\n",
        "            \"type\": \"single\",\n",
        "            \"answers\": [\n",
        "                \"Huffman coding\",\n",
        "                \"Byte pair encoding\",\n",
        "                \"Run-length encoding\",\n",
        "                \"Arithmetic coding\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Why is the LLaMA model considered more powerful than GPT-3 despite having fewer parameters?\",\n",
        "            \"type\": \"single\",\n",
        "            \"answers\": [\n",
        "                \"It uses a different architecture that is more efficient\",\n",
        "                \"It is trained with a larger vocabulary size\",\n",
        "                \"It is trained for a longer duration with more tokens\",\n",
        "                \"It uses fewer GPUs for training\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"What is a primary advantage of using RLHF (Reinforcement Learning from Human Feedback) over SFT (Supervised Fine-Tuning)?\",\n",
        "            \"type\": \"single\",\n",
        "            \"answers\": [\n",
        "                \"It requires less human intervention\",\n",
        "                \"It can generalize better across different tasks\",\n",
        "                \"It produces more diverse outputs\",\n",
        "                \"It works better according to human preference comparisons\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Which of the following is NOT a characteristic of base models as mentioned in the talk?\",\n",
        "            \"type\": \"single\",\n",
        "            \"answers\": [\n",
        "                \"They are designed to complete documents\",\n",
        "                \"They can be effectively used with prompt engineering\",\n",
        "                \"They are inherently designed to answer questions\",\n",
        "                \"They require significant computational resources for pretraining\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"What is a critical difference between System 1 and System 2 thinking in the context of LLMs as explained in the talk?\",\n",
        "            \"type\": \"single\",\n",
        "            \"answers\": [\n",
        "                \"System 1 is slower and deliberate, while System 2 is fast and automatic\",\n",
        "                \"System 1 involves fast and automatic processes, while System 2 is slow and deliberate\",\n",
        "                \"System 1 uses retrieval-augmented generation, while System 2 uses memory only\",\n",
        "                \"System 1 focuses on generating factual knowledge, while System 2 focuses on reasoning\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"What is the purpose of 'self-consistency' in prompting techniques as discussed in the talk?\",\n",
        "            \"type\": \"single\",\n",
        "            \"answers\": [\n",
        "                \"To ensure the model always generates the same output for the same input\",\n",
        "                \"To allow the model to generate multiple outputs and select the best one\",\n",
        "                \"To train the model to generate consistent outputs over time\",\n",
        "                \"To simplify the model's output for easier evaluation\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"According to the talk, what is a significant limitation of LLMs that impacts their use in high-stakes applications?\",\n",
        "            \"type\": \"single\",\n",
        "            \"answers\": [\n",
        "                \"Limited vocabulary size\",\n",
        "                \"Bias and hallucination of information\",\n",
        "                \"Inability to perform arithmetic calculations\",\n",
        "                \"Slow inference speed\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Which of the following techniques involves modifying the output probabilities of tokens to enforce a specific format, as mentioned in the talk?\",\n",
        "            \"type\": \"single\",\n",
        "            \"answers\": [\n",
        "                \"Retrieval-augmented generation\",\n",
        "                \"Constraint prompting\",\n",
        "                \"System 2 thinking\",\n",
        "                \"Reinforcement learning from human feedback\"\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "headers = {\n",
        "    'Authorization': f'Bearer {access_token}',\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "# Make the API request to create the poll\n",
        "response = requests.post(url, headers=headers, json=poll_data)\n",
        "\n",
        "if response.status_code == 201:\n",
        "    print(\"Poll created successfully!\")\n",
        "    print(response.json())\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}\")\n",
        "    print(response.json())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLrsvWOa_lZr",
        "outputId": "543ec170-8aa9-4e75-c519-3ae635ed65b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poll created successfully!\n",
            "{'id': 'cHIQMh1KTQ-K-UN89IyGTg', 'title': 'Technical Quiz', 'anonymous': False, 'status': 'notstart', 'questions': [{'name': 'Which of the following best describes the computational effort required for the pretraining stage in the GPT training pipeline?', 'type': 'single', 'answers': ['50% of the total training compute time', '75% of the total training compute time', '99% of the total training compute time', '25% of the total training compute time'], 'show_as_dropdown': False, 'answer_required': True}, {'name': 'What type of datasets form the training set for GPT pretraining according to the talk?', 'type': 'single', 'answers': ['Exclusively curated high-quality datasets', 'A mixture of web scraped data and high-quality datasets', 'Only web scraped data from CommonCrawl', 'Proprietary datasets only from GitHub and Wikipedia'], 'show_as_dropdown': False, 'answer_required': True}, {'name': 'In the tokenization process of GPT training, which of the following algorithms is mentioned as a typical method used?', 'type': 'single', 'answers': ['Huffman coding', 'Byte pair encoding', 'Run-length encoding', 'Arithmetic coding'], 'show_as_dropdown': False, 'answer_required': True}, {'name': 'Why is the LLaMA model considered more powerful than GPT-3 despite having fewer parameters?', 'type': 'single', 'answers': ['It uses a different architecture that is more efficient', 'It is trained with a larger vocabulary size', 'It is trained for a longer duration with more tokens', 'It uses fewer GPUs for training'], 'show_as_dropdown': False, 'answer_required': True}, {'name': 'What is a primary advantage of using RLHF (Reinforcement Learning from Human Feedback) over SFT (Supervised Fine-Tuning)?', 'type': 'single', 'answers': ['It requires less human intervention', 'It can generalize better across different tasks', 'It produces more diverse outputs', 'It works better according to human preference comparisons'], 'show_as_dropdown': False, 'answer_required': True}, {'name': 'Which of the following is NOT a characteristic of base models as mentioned in the talk?', 'type': 'single', 'answers': ['They are designed to complete documents', 'They can be effectively used with prompt engineering', 'They are inherently designed to answer questions', 'They require significant computational resources for pretraining'], 'show_as_dropdown': False, 'answer_required': True}, {'name': 'What is a critical difference between System 1 and System 2 thinking in the context of LLMs as explained in the talk?', 'type': 'single', 'answers': ['System 1 is slower and deliberate, while System 2 is fast and automatic', 'System 1 involves fast and automatic processes, while System 2 is slow and deliberate', 'System 1 uses retrieval-augmented generation, while System 2 uses memory only', 'System 1 focuses on generating factual knowledge, while System 2 focuses on reasoning'], 'show_as_dropdown': False, 'answer_required': True}, {'name': \"What is the purpose of 'self-consistency' in prompting techniques as discussed in the talk?\", 'type': 'single', 'answers': ['To ensure the model always generates the same output for the same input', 'To allow the model to generate multiple outputs and select the best one', 'To train the model to generate consistent outputs over time', \"To simplify the model's output for easier evaluation\"], 'show_as_dropdown': False, 'answer_required': True}, {'name': 'According to the talk, what is a significant limitation of LLMs that impacts their use in high-stakes applications?', 'type': 'single', 'answers': ['Limited vocabulary size', 'Bias and hallucination of information', 'Inability to perform arithmetic calculations', 'Slow inference speed'], 'show_as_dropdown': False, 'answer_required': True}, {'name': 'Which of the following techniques involves modifying the output probabilities of tokens to enforce a specific format, as mentioned in the talk?', 'type': 'single', 'answers': ['Retrieval-augmented generation', 'Constraint prompting', 'System 2 thinking', 'Reinforcement learning from human feedback'], 'show_as_dropdown': False, 'answer_required': True}], 'poll_type': 1}\n"
          ]
        }
      ]
    }
  ]
}